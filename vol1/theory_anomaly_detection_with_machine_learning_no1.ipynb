{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1変数のホテリング理論の詳細*\n",
    "(理論ガチガチの話なので、飛ばしても問題はありません。時間の都合上、Notebook上のみで言及します)  \n",
    "  \n",
    "**そもそも『最尤推定』とは？**  \n",
    "最尤推定とは、「ある観測結果が与えられたとき、尤度(ゆうど)と呼ばれる量が最大になるようにパラメータを決める」という手法です。  \n",
    "この尤度とは、「もっともらしさ」を意味します。つまり尤度が最大となるということは、最も「もっともらしい」ということになります。  \n",
    "  \n",
    "今回の体重の例でいえば、観測データとしては$N$個の体重が与えられています。この$N$個の体重が、それぞれ独立に正規分布の式\n",
    "  \n",
    "$$\n",
    "N(x|\\mu, \\sigma) \\equiv \\frac{1}{(2\\pi\\sigma^2)^\\frac{1}{2}}exp\\left\\{-\\frac{1}{(2\\sigma^2)^2}(x - \\mu)^2\\right\\}\n",
    "$$\n",
    "  \n",
    "に従うと仮定したとき、パラメータ$\\theta \\equiv \\left( \\mu, \\sigma^2 \\right)$の**尤度**(or **尤度関数**)は\n",
    "  \n",
    "$$\n",
    "p \\left( D| \\theta \\right) \\equiv \\prod_{n=1}^{N} N \\left( x^{(n)}| \\mu, \\sigma^2 \\right)\n",
    "$$\n",
    "  \n",
    "で**定義**されます。(定義なので、文句は言わないでください。これは決まり事。)  \n",
    "  \n",
    "各観測データは独立と仮定しましたが、例えば、一郎さんが70kgだからといって次郎さんも同様な体重となる理由はない、ということです。  \n",
    "※各観測データが独立でない場合の話は、第7,8回あたりで説明します。  \n",
    "  \n",
    "この定義された式をそのまま利用してもいいのですが、実際の計算を楽にするために自然対数をとります。  \n",
    "※計算を楽にするために、よくやるやり方→指数関数的に変化されるより自然対数をとって線形的な変化で捉える方が楽、的な  \n",
    "  \n",
    "なので、自然対数をとると、  \n",
    "$$\n",
    "L\\left(\\theta|D \\right) \\equiv Inp \\left( D| \\theta \\right) = - \\frac{N}{2} In\\left(2\\pi\\sigma^2\\right) - \\frac{1}{2\\sigma^2}\\sum_{n=1}^{N} \\left(x^{(n)} - \\mu \\right)^2\n",
    "$$\n",
    "  \n",
    "これを最大化するパラメータこそ、観測データDにとって最も当てはまる、もっとも尤もらしいパラメータとなります。  \n",
    "最大化するパラメータ$\\mu$と$\\sigma^2$を探すためにはこの式を、$\\mu$と$\\sigma^{-2}$でそれぞれ微分してゼロとなるときを計算すれば良いので  \n",
    "  \n",
    "$$\n",
    "0 = \\frac {\\partial L}{\\partial \\mu} =  - \\frac{1}{\\sigma^2}\\sum_{n=1}^{N} \\left(x^{(n)} - \\mu \\right)\n",
    "$$\n",
    "  \n",
    "$$\n",
    "0 = \\frac {\\partial L}{\\partial \\sigma^{-2}} =  \\frac{N}{2\\sigma^{-2}} - \\frac{1}{2}\\sum_{n=1}^{N} \\left(x^{(n)} - \\mu \\right)^2\n",
    "$$\n",
    "  \n",
    "この二つを計算すると、  \n",
    "$$\n",
    "{\\mu} = \\frac{1}{N}\\sum_{n=1}^{N} x^{(n)}\n",
    "$$\n",
    "  \n",
    "$$\n",
    "{\\sigma}^{2} = \\frac{1}{N}\\sum_{n=1}^{N} \\left(x^{(n)} - \\hat{\\mu}\\right)^2\n",
    "$$\n",
    "  \n",
    "が得られます。  \n",
    "  \n",
    "**異常度$a(x^{'})$確率分布(1変数)**  \n",
    "$$\n",
    "a(\\boldsymbol{x}^{'}) \\equiv \\frac{1}{\\hat{\\sigma}^2} \\left(x^{'} - \\hat{\\mu} \\right)^{2}\n",
    "$$\n",
    "異常度$a(x^{'})$確率分布を求めるには、次の三つの問いに答える必要があります。  \n",
    "  \n",
    "(1) $a(x^{'})$の分子 $x^{'} - \\hat \\mu $の確率分布はなに？  \n",
    "(2) $a(x^{'})$の分母 $\\hat \\sigma^2$の確率分布はなに？  \n",
    "(3) 両者の比の確率分布はなに？  \n",
    "  \n",
    "まず、一つ目の問いから考えていきます。  \n",
    "**定理(1次元正規変数の１次結合)**  \n",
    "$x$と$x^{'}$が独立に正規分布$N(\\mu, \\sigma^2)$に従うとき、  \n",
    "ある定数$a$と$b$によりつくられる確率変数 $ax+bx^{'}$は、平均$(a + b)\\mu$,  分散$\\sigma^2(a^2 + b^2)$に従う\n",
    "  \n",
    "この定理は、直感的に理解すると、例えば、１人の体重の平均が60kgなら、２人分の体重は120kg前後になることは予想できます。  \n",
    "分散(ばらつき)についても、２人分を考えるとそのばらつき具合を考えれば、また２人の合算になります。  \n",
    "正規分布は平均と分散で特徴付けられますので、それぞれ平均と分散の期待値を計算してみます。  \n",
    "※期待値を計算するということは、ある意味「予測」を示します\n",
    "※期待値の公式 $N$個の観測値$\\left[x_{1}, x_{2}, ... , x_{N}\\right]$に対してそれぞれ確率が$\\left[p_{1}, p_{2}, ... , p_{N}\\right]$  \n",
    "　と与えられたときの期待値は $x_{1}*p_{1} + x_{2}*p_{2} + ... + x_{N}*p_{N}$となります\n",
    "  \n",
    "ある観測点x^{'}について平均は、$ax+bx^{'}$の期待値であり分散は、$\\{(ax+bx^{'}) - (\\mu+b\\mu)\\}^2$の期待値です。これを展開して整理すると、  \n",
    "$$\n",
    "a^{2}(x-\\mu)^{2}+b^{2}(x^{'}-\\mu)^{2}+2ab(x-\\mu)(x^{'}-\\mu)\n",
    "$$\n",
    "の期待値ということになりますが、$(x-\\mu)^{2}$と$(x^{'}-\\mu)^{2}$の期待値は$\\sigma^{2}$になり、$(x-\\mu)$の期待値はゼロなので、  \n",
    "結局、分散は$(a^{2}+b^{2})\\sigma^{2}$となります。  \n",
    "量$x^{'}-\\hat\\mu$は、N+1個の独立な確率変数$x^{(1)}, x^{(2)}, ... , x^{(N)}, x^{'}$の１次結合として表せますから、この確率変数が従う分布の  \n",
    "平均と分散が、それぞれ  \n",
    "$$\n",
    "\\mu\\left\\{\\frac{1}{N}+\\frac{1}{N}+...+\\frac{1}{N}+(-1)\\right\\} = 0, \\sigma^{2}\\left\\{\\frac{1}{N^{2}}+...+\\frac{1}{N^{2}}+(-1)^{2}\\right\\}\n",
    "$$\n",
    "  \n",
    "となることがわかります。改めて上記式を書き直すと次のようになります。  \n",
    "  \n",
    "$$\n",
    "x^{'}-\\hat\\mu \\sim N\\left(x^{'}-\\hat\\mu | 0, \\frac{N+1}{N}\\sigma^{2}\\right) \n",
    "$$\n",
    "  \n",
    "これは観測値と標本平均の差のばらつきについての分布です。  \n",
    "観測値がばらつくのは当然ですが、標本平均$\\hat\\mu$のばらつきも考慮していることに注意してください。  \n",
    "標本平均はデータが決まればただ１つに確定する値となります。そして、そのばらつきを現実的に考えることはありません。  \n",
    "  \n",
    "**この現実的に考えることのない、ばらつきを、データ自体の不十分さ、不確定さまでを考えてくれるのが、このホテリング理論のすごさ**となります。  \n",
    "  \n",
    "ただし、標本が1,000個とか10,000個があり、$N \\gg 1$が成り立つ状況では、$x^{'}-\\hat\\mu$は分布$N(0, \\sigma^{2})$にほぼ従います。  \n",
    "これは、標本平均を真の平均とみなした場合の結果と同様となります。  \n",
    "この分布においては、$\\sigma^{2}$という量が含まれます。これは真の分布のパラメータですので未知量であり、これがわからない限り何も言えない  \n",
    "ですが、最終的には、異常度の分布を考えると、分母と分子でこの未知量が打ち消し合い、未知量によらない分布が現れます。  \n",
    "これがホテリング理論の見所となります。  \n",
    "  \n",
    "最終に行く前に、$a(x^{'})$の分母$\\sigma^{2}$の確率分布について考えます。  \n",
    "これについて次の定理が必要となります。  \n",
    "  \n",
    "**定理(1次元正規変数の平方和の分布)**  \n",
    "$N(0, \\sigma^{2})$に独立に従う$N$個の確率変数$x^{(1)}, x^{(2)}, ... , x^{(N)}$と、定数$a>0$により定義される確率変数  \n",
    "$$\n",
    "\\mu \\equiv a(x_{1}^{2}+x_{2}^{2}+...+x_{N}^{2})\n",
    "$$\n",
    "は、自由度$N$, スケール因子$a\\sigma^{2}$のカイ二乗分布$\\chi^{2}(u| N, a\\sigma^{2})$に従う  \n",
    "  \n",
    "この事実は確率分布の定義から直接示すことができます。確率変数$\\mu$の確率密度関数$q(\\mu)$は形式的に次のように書けます。  \n",
    "$$\n",
    "q(u) = \\int_{-\\infty}^{\\infty} dx_{1}\\cdot\\cdot\\cdot dx_{N}\\delta \\left(u-a(x_{1}^{2}+\\cdot\\cdot\\cdot+x_{N}^{2}) \\right) \\prod_{n=1}^{N} N(x_{N}|0, \\sigma^{2})\n",
    "$$\n",
    "  \n",
    "ここで、被積分関数は変数の二乗和にのみ依存しますので、$N$次元球座標に変数変換するのが便利です。  \n",
    "動径座標を$r$, $N$次元空間内での単位球表面の面素を$dS_{1,N}$とおくと、次の式が得られます。  \n",
    "  \n",
    "$$\n",
    "dx_{1}\\cdot\\cdot\\cdot dx_{N} = drr^{N-1}dS_{1,N}\n",
    "$$\n",
    "  \n",
    "さらに$v=ar^{2}$, $r=\\sqrt{v/a}$により$r$, $v$に積分変数を変換すると、  \n",
    "  \n",
    "$$\n",
    "dx_{1}\\cdot\\cdot\\cdot dx_{N} = drr^{N-1}dS_{1,N} = \\frac{dv}{2a}\\left( \\frac{v}{a} \\right)^{(N/2)-1}dS_{1,N}\n",
    "$$\n",
    "  \n",
    "となります。これを使うと$q(u)$は  \n",
    "$$\n",
    "q(u) = \\int_{-\\infty}^{\\infty} \\frac{dv}{2a}\\left( \\frac{v}{a} \\right)^{(N/2)-1}\\delta(u-v)(2\\pi\\sigma^{2})^{-N/2}e^{-v/(2\\pi\\sigma^{2})} \\int dS_{1,N}\n",
    "$$\n",
    "  \n",
    "となります。このvの積分については、デルタ関数の一般的性質  \n",
    "  \n",
    "$$\n",
    "\\int dx \\delta(x-a)f(x) = f(a) \n",
    "$$\n",
    "  \n",
    "を使うことで単位球の表面積は  \n",
    "  \n",
    "$$\n",
    "S_{1,N} \\equiv \\int dS_{1,N} = \\frac{2\\pi^{N/2}}{\\Gamma(N/2)}\n",
    "$$\n",
    "  \n",
    "となります。これはよく知られた結果ですが、証明は別の機会にします。  \n",
    "以上をまとめると、確率変数$u$の確率密度関数$q(u)$は最終的に次のような式になります。\n",
    "  \n",
    "$$\n",
    "q(u) = \\frac{1}{2a\\sigma^{2}\\Gamma(N/2)}\\left( \\frac{u}{2a\\sigma^{2}} \\right)^{(N/2)-1}exp\\left(-\\frac{u}{2a\\sigma^{2}} \\right)\n",
    "$$  \n",
    "  \n",
    "これは自由度$N$, スケール因子$a\\sigma^{2}$のカイ二乗分布となります。  \n",
    "この**カイ二乗分布の自由度は「独立な正規変数が何個あったか」** を示しています。独立変数の数だけ自由に動けるということで、自由度といっています。  \n",
    "観測値と標本平均の差のばらつきについての分布 $(x^{'}-\\hat\\mu) \\sim N\\left( 0, \\frac{N+1}{N}\\sigma^{2}\\right)$の２乗について、  \n",
    "上記式より、次のように整理できます。  \n",
    "$$\n",
    "(x^{'}-\\hat\\mu)^{2} \\sim \\chi^{2} \\left( 1, \\frac{N+1}{N}\\sigma^{2}\\right)\n",
    "$$\n",
    "  \n",
    "一方、標本分散$\\hat\\sigma^{2}$の式 ${\\sigma}^{2} = \\frac{1}{N} \\sum_{n=1}^{N} \\left(x^{(n)} - \\hat{\\mu}\\right)^2$を見ると、$N$個の項の二乗和の形になっていて、標本平均$\\hat\\mu$を有していることが、  \n",
    "それぞれの「独立性」を持たせられない要因となっています。  \n",
    "そこで先ほどの定理と次の定理とを合わせつつ、独立な正規変数の二乗和の形に持っていく必要があります。  \n",
    "  \n",
    "**定理(標本分散の自由度)**  \n",
    "$N$次元の確率変数ベクトル$X \\equiv [x^{(1)}, x^{(2)}, ... , x^{(N)}]^T$の各次元が独立に$N(\\mu, \\sigma^{2})$に従うとする。このとき  \n",
    "1. $N \\times N$の任意の直行行列$U$を与えたとき、直交変換$Y = U^{T}X$により定義される確率変数ベクトル$Y$の各次元$y_{1}, ..., y_{N}$は  \n",
    "やはり互いに独立で分散$\\sigma^{2}$の正規分布をなす。  \n",
    "2. さらに、うまく$U$を選択すれば、${\\sigma}^{2} = \\frac{1}{N} \\sum_{n=1}^{N} \\left(x^{(n)} - \\hat{\\mu}\\right)^2$の標本分散$\\hat\\sigma^{2}$を  \n",
    "$$\n",
    "\\hat\\sigma^{2} = \\frac{1}{N} \\sum_{n=2}^{N}y_{n}^{2}\n",
    "$$\n",
    "の形に変換することができる。これに含まれない$y_{1}$は、$y_{1}=\\sqrt{N}\\hat\\mu$を満たす。したがって、$\\hat\\sigma^{2}$は$\\hat\\mu$とは統計的に独立である。  \n",
    "3. 標本分散$\\hat\\sigma^{2}$は、自由度$N-1$, スケール因子$sigma^{2}/N$のカイ二乗分布に従う。  \n",
    "  \n",
    "この定理を用いて、標本分散$\\hat\\sigma^{2}$の式 ${\\sigma}^{2} = \\frac{1}{N} \\sum_{n=1}^{N} \\left(x^{(n)} - \\hat{\\mu}\\right)^2$の独立性を考えていきます。  \n",
    "ここでひとまずの目標としては、確率密度分布の各項$y_{i}$について積の形になってさえいれば独立であることが示せます。  \n",
    "$X$の同時分布は正規分布の積になりますが、これは\n",
    "$$\n",
    "p(X) \\ltimes exp \\left \\{ - \\frac{1}{2\\sigma^{2}}(X-\\mu1_{N})^{T} (X - \\mu1_{N}) \\right)\n",
    "$$\n",
    "という形となっています。ただし、$1_{N}$は要素がすべて$1$である$N$次元ベクトルの直交行列$Y=U^{T}X$により定義される確率変数$Y$の分布は、\n",
    "$$\n",
    "p(Y) \\ltimes exp \\left \\{ - \\frac{1}{2\\sigma^{2}}(Y-\\mu U^{T}1_{N})^{T} (Y - \\mu U^{T}1_{N}) \\right)\n",
    "$$\n",
    "  \n",
    "ここで、直交行列の性質$U^{T}U=UU^{T} = I_{N}$を使いました。$ I_{N}$は$N$次元の単位行列です。これが各成分ごとの積の形になっており、  \n",
    "それぞれが分散$\\sigma^{2}$の1次元正規分布となっています。  \n",
    "  \n",
    "次に、$U$をうまく選択することで標本分散がを２次形式の標準形に直せることを示していきます。これは$N$個の変数$x^{(1)}, x^{(2)}, ... , x^{(N)}$からなる  \n",
    "２次形式${\\sigma}^{2} = \\frac{1}{N} \\sum_{n=1}^{N} \\left(x^{(n)} - \\hat{\\mu}\\right)^2$の主軸問題になります。  \n",
    "まず標本平均$\\hat\\mu$が、$N$次元ベクトル同士の内積として  \n",
    "  \n",
    "$$\n",
    "\\hat\\mu = \\frac{1}{N}1_{N}^{T}X\n",
    "$$\n",
    "  \n",
    "と表せることに注意します。これを使うと、標本分散$\\hat\\sigma^{2}$は次のように表せます。  \n",
    "  \n",
    "$$\n",
    "\\hat\\sigma^{2} = \\frac{1}{N}X^{T}H_{N}X\n",
    "$$\n",
    "ただし, \n",
    "$$\n",
    "H_{N} \\equiv I_{N}-\\frac{1}{N}1_{N}1_{N}^{T}\n",
    "$$\n",
    "  \n",
    "ここで行列$H_{N}$は、**中心化行列** といいます。次に、直交変換$X=UY$により、この２次形式が  \n",
    "  \n",
    "$$\n",
    "\\hat\\sigma^{2} = \\frac{1}{N}Y^{T}U^{T}H_{N}UY = \\frac{1}{N}\\sum_{n=1}^{N}\\lambda_{n}y_{n}^{2}\n",
    "$$\n",
    "  \n",
    "の形となるように直交行列$U$を選択します。$H_{N} \\equiv I_{N}-\\frac{1}{N}1_{N}1_{N}^{T}$から、$U$は  \n",
    "  \n",
    "$$\n",
    "U^{T}H_{N}U=diag(\\lambda_{1}, \\lambda_{2}, ... , \\lambda_{N})\n",
    "$$\n",
    "  \n",
    "を満たす必要があります。この$diag$は括弧内のスカラーを対角要素に順に並べた対角行列です。これは線形代数のお話となります。  \n",
    "丁寧に説明すると、$H_{N}$の固有値問題と同様で、$\\lambda_{i}$はその固有値と一致します。また、$U$の第$i$列は固有値$\\lambda_{i}$に対応する$H_{N}$の固有ベクトルです。  \n",
    "$H_{N}$の固有値方程式を書くと、  \n",
    "  \n",
    "$$\n",
    "0 = |H_{N} - \\lambda I_{N} | = | (1-\\lambda)I_{N} - \\frac{1}{N}1_{N}1_{N}^{T} | = (1-\\lambda)^{N}| l_{N} - \\frac{1}{(1-\\lambda)N}1_{N}1_{N}^{T} | \n",
    "$$\n",
    "  \n",
    "となりますが、最右辺の行列式は、[シルベスターの行列式補題](https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%AB%E3%83%99%E3%82%B9%E3%82%BF%E3%83%BC%E8%A1%8C%E5%88%97)により$1-\\frac{1}{(1-\\lambda)N}1_{N}1_{N}^{T}$となります。結局、  \n",
    "  \n",
    "$$\n",
    "-\\lambda(1-\\lambda)^{N-1} = 0\n",
    "$$\n",
    "  \n",
    "が解くべき固有値方程式となります。  \n",
    "すなわち$H_{N}$の固有値は一つだけが$0(\\lambda_{1}=0)$で、残りの$N-1$個はすべて1となります$(\\lambda_{2}=\\lambda_{3}=\\cdot\\cdot\\cdot=\\lambda_{N}=1)$。  \n",
    "これらを先ほどの式$\\hat\\sigma^{2} = \\frac{1}{N}Y^{T}U^{T}H_{N}UY = \\frac{1}{N}\\sum_{n=1}^{N}\\lambda_{n}y_{n}^{2}$に代入することで式$\\hat\\sigma^{2} = \\frac{1}{N} \\sum_{n=2}^{N}y_{n}^{2}$を得ます。  \n",
    "また、$\\lambda_{1}=0$に対応する固有値ベクトル$u_{1}$は、$H_{N}u_{1}=0\\cdot u_{1}$を満たす必要があります。  \n",
    "  \n",
    "ここで、$u_{1} \\ltimes 1_{N}$であり、直交条件$u_{1}^{T}u_{1}=1$から、$u_{1}=1_{N}/ \\sqrt{N}$となります。直交変換$Y=U^{T}X$と$\\hat\\sigma^{2} = \\frac{1}{N}X^{T}H_{N}X$と合わせて、新たな確率変数  \n",
    "$$\n",
    "y_{1}=u_{1}^{T}X=\\frac{1}{\\sqrt{N}}1_{N}^{T}X=\\sqrt{N}\\hat\\mu\n",
    "$$\n",
    "を得ることができます。  \n",
    "$\\sigma^{2}$と$y_{1}$は独立であるから、$\\hat\\mu$も独立となります。これで先ほどの定理の2.を証明できました。  \n",
    "また、定理(1次元正規変数の平方和の分布)と式$\\hat\\sigma^{2} = \\frac{1}{N}X^{T}H_{N}X$から  \n",
    "$$\n",
    "\\hat\\sigma^{2} \\sim \\chi^{2} \\left( N-1, \\frac{1}{N}\\sigma^{2} \\right)\n",
    "$$\n",
    "となります。これで定理(標本分散の自由度)は証明自体終わりました。  \n",
    "この式は、標本分散がどういうばらつきをもちうるか、を表しています。最尤推定量としての標本分散を、データから一意にきまるただの数値ではなく、  \n",
    "データのばらつきの可能性をも考えた確率変数として取り扱っているところが、ホテリング理論のポイントとなります。  \n",
    "しかしながら、真の分布の分散という未知のパラメータをまだ含んでいるため、実用的ではありません。  \n",
    "異常度の最終的な分布においては一切未知のパラメータが含まれないことを示すために、最後に、カイ二乗分布とF分布をみていきます。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ホテリング統計量の確率分布(1次元)\n",
    "これまでの流れで、ようやく$a(\\boldsymbol{x}^{'}) \\equiv \\frac{1}{\\hat{\\sigma}^2} \\left(x^{'} - \\hat{\\mu} \\right)^{2} = \\left(x^{'} - \\hat{\\mu} \\right)^{2}$で定義される$a(x^{'})$の分子と分母が独立にカイ二乗分布に従ってることがわかりました。  \n",
    "このカイ二乗分布の比の確率密度分布は解析的に求めることが可能で、それが先に示した$F$分布です。  \n",
    "  \n",
    "**定理(カイ二乗分布の比とF分布)**  \n",
    "$x$が自由度$m$, スケール因子$a$のカイ二乗分布に従い、$y$が自由度$n$, スケール因子$b$のカイ二乗分布に従う。このとき\n",
    "  \n",
    "$$\n",
    "f \\equiv \\frac{x/(am)}{bn}\n",
    "$$\n",
    "  \n",
    "により定義される確率変数$f$は、自由度$(m, n)$の$F$分布をなす。その確率密度分布は式\n",
    "  \n",
    "$$\n",
    "F(m, n) \\equiv \\frac{1}{B(m/2, n/2)}\\left ( \\frac{m}{n} \\right)^{m/2} u^{(m/2)-1} \\left(1+\\frac{mu}{n} \\right)^{-(m+n)/2}\n",
    "$$\n",
    "  \n",
    "で与えられる。  \n",
    "  \n",
    "これもまた、定理(標本分散の自由度)の証明同様、確率分布の定義から直接示すことができます。  \n",
    "確率変数${x^{1}, ..., x^{M}}$の定義域$R$において、任意の$z$に対して$z=f(x^{1}, ..., x^{M})$を満たす確率を合計したものに比例するという確率変数の変換公式  \n",
    "  \n",
    "$$\n",
    "q(z) = \\int_{R}dx \\delta(z-f(x^{1}, ..., x^{M}))p(x_{1}, ..., x_{M})\n",
    "$$\n",
    "  \n",
    "によれば、$f$の確率密度分布$q(f)$は形式的に次のようにかけます。  \n",
    "  \n",
    "$$\n",
    "q(f) = \\int_{0}^{\\infty}dx\\int_{0}^{\\infty}dy\\delta\\left \\{ f-\\frac{1}{B(m/2, n/2)} \\right \\}\\chi^{2}(x|m,a)\\chi^{2}(y|n,b)\n",
    "$$\n",
    "  \n",
    "まず$x$についての積分を先に実行するものとし、$x$を$u=bnx/(amy)$と変数変換します。それにより、次の計算ができます。  \n",
    "  \n",
    "$$\n",
    "q(f) = \\int_{0}^{\\infty}dy\\frac{amy}{bn}\\int_{0}^{\\infty}du\\delta(u-f)\\chi^{2}\\left(\\frac{amyf}{bn}|m,a\\right)\\chi^{2}(y|n,b)\n",
    "= \\int_{0}^{\\infty}dy\\frac{amy}{bn}\\chi^{2}\\left(\\frac{amyu}{bn}|m,a \\right)\\chi^{2}(y|n,b)\n",
    "$$\n",
    "  \n",
    "カイ二乗分布の定義式\n",
    "  \n",
    "$$\n",
    "\\chi^{2}(u|k, s) \\equiv \\frac{1}{2s\\Gamma(k/2)} \\left( \\frac{u}{2s} \\right)^{(k/2)-1}exp(-\\frac{u}{2s})\n",
    "$$\n",
    "$$\n",
    "\\Gamma(z) \\equiv \\int_{0}^{\\infty}dtt^{z-1}e^{-t}\n",
    "$$\n",
    "  \n",
    "を用いて被積分関数を整理すると、\n",
    "$$\n",
    "\\frac{1}{2bf\\Gamma(m/2)\\Gamma(n/2)}\\left( \\frac{n}{mf} \\right)^{m/2}\\left( \\frac{y}{2b} \\right)^{\\{(m+n)/2\\}-1}exp\\left\\{-\\frac{y}{2b}\\left( 1+\\frac{mf}{n}\\right) \\right\\}\n",
    "$$\n",
    "  \n",
    "となりますが、よく見るとこれは自由度$m+n$, スケール因子$s \\equiv b\\{ 1+(mf)/n\\}^{-1}$のカイ二乗分布に比例していることがわかります。  \n",
    "すなわち被積分関数は  \n",
    "$$\n",
    "\\frac{1}{gB(m/2, n/2)}\\left( \\frac{mf}{n} \\right)^{m/2}\\left( 1+\\frac{mf}{n}\\right)^{-(m+n)/2}\\chi^{2}(y|m+n,s)\n",
    "$$\n",
    "  \n",
    "であり、$y$の積分をカイ二乗分布の規格化条件を用いて実行すると、$q(f)$が$F$分布の確率密度関数になりことがわかります。  \n",
    "これで定理(カイ二乗分布の比とF分布)が証明されました。  \n",
    "さて、異常度の定義  \n",
    "$$\n",
    "a(x^{'}) = \\frac{(x^{'}-\\hat\\mu)^{2}}{\\sigma^{2}}\n",
    "$$\n",
    "に戻り、さきに結果だけを示した定理(ホテリング統計量の分布(1変数))(※勉強会第1回ノートブック最後の定理)を証明しましょう。  \n",
    "  \n",
    "上式中、分母分子とも、カイ二乗分布に従うことをすでに示しました。  \n",
    "改めてまとめると、  \n",
    "(1)\n",
    "$$\n",
    "(x^{'}-\\hat\\mu^{2}) \\sim \\chi^{2} \\left( 1, \\frac{N+1}{N}\\sigma^{2} \\right)\n",
    "$$\n",
    "(2)\n",
    "$$\n",
    "\\hat\\sigma^{2} \\sim \\chi^{2} \\left( N-1, \\frac{1}{N}\\sigma^{2} \\right)\n",
    "$$\n",
    "これらは未知のパラメータ$\\sigma^{2}$を含んでいますが、両者の比の結果は  \n",
    "$$\n",
    "\\frac{N-1}{N+1}a(x^{'})\n",
    "$$\n",
    "を作ることで、その課題はクリアできます。  \n",
    "定理(カイ二乗分布の比とF分布)によれば、これが自由度$(1, N-1)$のF分布に従う、ということがわかりました。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
